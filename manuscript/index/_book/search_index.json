[
["index.html", "Introduction", " Introduction ASReview takes the following parameters/arguments: a model a query strategy a balance strategy (fixed) a feature extraction strategy number of training data The model is typically a learning algorithm used to predict the relevance of text. The following models will be compared: Naive Bayes (nb) (???). If you feel it necessary to include an appendix, it goes here. --> "],
["A-parameter-configurations.html", "A Parameter Configurations", " A Parameter Configurations model: nb query_strategy: max balance_strategy: double feature_extraction: tfidf n_instances: 1 n_queries: 10 n_prior_included: 5 n_prior_excluded: 5 mode: simulate model_param: {} query_param: {} feature_param: {} balance_param: {} abstract_only: False This leads to 273 combinations of configurations. Naive bayes only goes with tfidf feature extraction. For the feature extraction strategies we will focus on doc2vec and tfidf. (but will compute all 4) This leads to 3 * 7 * 4 * 3 + 1 * 7 * 1 * 3 = 273 combinations. "],
["B-list-of-definitions.html", "B List of Definitions", " B List of Definitions Model. The prediction model for Active learning some code, part of Definition 2 Third paragraph of definition 2. Query Strategy Type of active learning, determining the way papers are queried to the researcher. query_strategy Uncertainty sampling Selects the least sure instances for labelling. Maximum sampling Selects the samples with the highest prediction probability. The references who are most likely to be included are presented first. Random and maximum sampling. Combination of random and maximum sampling. By default samples the 95% of the instances with max sampling, and 5% of the samples with random sampling. Feature Extraction Strategy The way the words in the abstracts are represented in the statistical model. feature_extraction Doc2Vec doc2vec Term frequency-inverse document frequency (tf-idf) sbert "],
["references.html", "References", " References "]
]
