% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={A Minimal Book Example},
  pdfauthor={Yihui Xie},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{A Minimal Book Example}
\author{Yihui Xie}
\date{2020-02-25}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{thesis-ferdinands}{%
\chapter{thesis Ferdinands}\label{thesis-ferdinands}}

Goal: evaluate performance of different models of the ASReview tool.

\hypertarget{stage-1-hyperparameter-optimization}{%
\subsection{Stage 1: hyperparameter optimization}\label{stage-1-hyperparameter-optimization}}

We are testing 5 models on 5 different datasets.

Every model has its own set of hyperparameters.
The hyperparameters are optimized on the 5 datasets in three different ways:

\begin{itemize}
\tightlist
\item
  1 on 1: maximum performance
\item
  4 on 1: cross-validation
\item
  5 on 1: more data = more better?
\end{itemize}

This results \((5+5+1)*5\) sets of hyperparameters.

\hypertarget{stage-2-simulation}{%
\subsection{Stage 2: simulation}\label{stage-2-simulation}}

for every for every model (5), for every dataset (5) and for every set of optimized hyperparameters (3), a simulation study is performed. From these \(5*5*3=75\) simulation studies, performance of the different models is evaluated.

\hypertarget{scripts}{%
\section{Scripts}\label{scripts}}

\begin{itemize}
\tightlist
\item
  simulatie:
\item[$\square$]
  script die optimalisatie genereert (config files.)
\item[$\square$]
  script die \texttt{.ini}'s voor simulatie genereert.
\end{itemize}

\hypertarget{introduction-intro}{%
\chapter{Introduction (\#intro)}\label{introduction-intro}}

SR are booming
ML tools as well

\citep{PRISMA-PGroup2015}

What must be the objective of our tool?

Selecting papers is a two-step process: abstract \& fulltext screening

\hypertarget{current-solutions}{%
\section{Current solutions}\label{current-solutions}}

Workload savings 30-70 percent, at a loss of 5\% of relevant studies \citep{Omara-Eves2015}.

\hypertarget{methods-methods}{%
\chapter{Methods (\#methods)}\label{methods-methods}}

Goal: evaluate performance of different models of the ASReview tool.
The screening process is simulated using ASReview, seeing if the original inclusions replicate.
annotated include/exclude

\hypertarget{datasets}{%
\section{Datasets}\label{datasets}}

The data consists of five open datasets on systematic reviews from various research areas.
All datasets are openly available.
The raw files were preprocessed. Duplicate entries were removed.
Entries with missing abstracts were removed.
Preprocessing scripts can be found on the GitHub repository

Descriptive statistics on the five systematic reviews can be found in Table Table 1.

\begin{table}

\caption{\label{tab:unnamed-chunk-5}Table  1: Descriptive statistics on articles and resulting datasets for each original systematic review.}
\centering
\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X}
\toprule
\multicolumn{1}{c}{} & \multicolumn{4}{c}{Original study} & \multicolumn{4}{c}{Test collection} \\
\cmidrule(l{3pt}r{3pt}){2-5} \cmidrule(l{3pt}r{3pt}){6-9}
Dataset & No. studies & No. selected for fulltext screening & No. final inclusions & Inclusion rate (\%) & No. studies in test collection & No. selected for fulltext screening test collection & No. final inclusions in test collection & Inclusion rate in test collection (\%)\\
\midrule
nudging & 2006 & 377 & 100 & 4.99 & 2018 & NA & 118 & 5.85\\
wilson & 3453 & 174 & 26 & 0.75 & 3437 & 174 & 26 & 0.76\\
ptsd & 6185 & 363 & 34 & 0.55 & 5782 & 356 & 38 & 0.66\\
software & 8911 & NA & 106 & 1.19 & 8911 & NA & 104 & 1.17\\
ace & 2544 & NA & 41 & 1.61 & 2544 & NA & 41 & 1.61\\
\bottomrule
\end{tabu}
\end{table}

The inclusion rate is \ldots{} data is imbalanced.
what is the philosophy
False negatives must be avoided \ldots{}
The cost of a false negative outweighs the cost of a false positive.
Note that we assume the oracle/original user to hold the truth.
This is of course not always the case.

\hypertarget{models}{%
\section{Models}\label{models}}

Five different models were applied on the data.

\hypertarget{optimizing-hyperparameters}{%
\subsection{Optimizing Hyperparameters}\label{optimizing-hyperparameters}}

Every model has its own hyperparameters.
For every model, the hyperparameters are optimized three times, arriving at three versions of the model:

\hypertarget{the-software}{%
\chapter{The software}\label{the-software}}

ASReview takes the following parameters/arguments:

\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X}
\toprule
  & Configurations\\
\midrule
Models & Naive Bayes, Random Forest, Support Vector Machine, Logistic Regression\\
Query Strategies & Cluster Sampling, Maximum Sampling, Cluster * Maximum  Sampling, Maximum * Uncertainty Sampling, Maximum * Random Sampling, Cluster * Uncertainty Sampling, Cluster * Random Sampling\\
Feature extraction strategies & Doc2Vec, TF-IDF, sbert, embeddingIdf\\
\bottomrule
\end{tabu}

Use these inputs to predict relevance of papers.

\hypertarget{stage-1-hyperparameter-optimization-1}{%
\subsection{Stage 1: hyperparameter optimization}\label{stage-1-hyperparameter-optimization-1}}

We are going to test 5 models on 5 different datasets.

\hypertarget{ace}{%
\subsubsection{ACE}\label{ace}}

The ACEInhibitors dataset from the study by \citep{Cohen2006}. a machine learning-based citation classification tool to reduce workload in systematic reviews of drug class efficacy.

\href{mailto:WSS@95}{\nolinkurl{WSS@95}}\% = 56.61 in \citep{Cohen2006}. (5x2 crossvalidation). Can we beat this?
The data

\hypertarget{ptsd}{%
\subsubsection{ptsd}\label{ptsd}}

The review\\
The data

\hypertarget{hall}{%
\subsubsection{hall}\label{hall}}

The review \citep{Hall2012}, is reviewed in \citep{Yu2016}.

\hypertarget{nudging}{%
\subsubsection{nudging}\label{nudging}}

The review \citep{Nagtegaal2019}
The data \citep{Nagtegaal2019a}

Paper says:
- systematic search n = 2006
- full text screening n = 377
- included in synthesis n = 100

Open data online says:

\begin{itemize}
\tightlist
\item
  systematic search n =
\item
  full text screening n =
\item
  included in synthesis n = 101 (18?)
\end{itemize}

abstract excel sheet private says:
- systematic search n = 2018
- full text screening n =
- included in synthesis n = 118

Difference in 18 inclusions = systematic reviews. to exclude/include?

\hypertarget{wilson}{%
\subsubsection{Wilson}\label{wilson}}

The review \citep{Appenzeller-Herzog2019}
The dataset \citep{Appenzeller-Herzog2020}

\begin{itemize}
\tightlist
\item
  systematic search n = 3453
\item
  full text screening n = 174
\item
  included in synthesis n = 26
\end{itemize}

\hypertarget{models-1}{%
\subsection{Models}\label{models-1}}

\begin{itemize}
\tightlist
\item
  Naive Bayes
\item
  Random Forests
\item
  Support Vecor Machine
\item
  Logistic Regression
\item
  Dense Neural Network
\end{itemize}

Or, more specific:

\begin{tabular}{ll}
\toprule
Models & Feature extraction strategies\\
\midrule
nb & tfidf\\
rf & tfidf\\
svm & tfidf\\
lr & doc2vec\\
NA & NA\\
\bottomrule
\end{tabular}

The other parameters remain fixed over the 5 models:

\begin{itemize}
\tightlist
\item
  Query Strategy = max
\item
  Balance Strategy = triple
\item
  n\_instances=10 (number of papers each query)
\item
  n\_prior\_included = 5
\item
  n\_prior\_excluded = 5
\end{itemize}

\hypertarget{hyperparameters}{%
\subsection{Hyperparameters}\label{hyperparameters}}

Every model has its own set of hyperparameters:

\hypertarget{optimization}{%
\subsection{Optimization}\label{optimization}}

The hyperparameters are optimized on the 5 datasets in three different ways:

\begin{itemize}
\tightlist
\item
  1 on 1: maximum performance
\end{itemize}

\[ d = D \]
- 4 on 1: cross-validation
\[ d \notin D\]

\[ D = {1, 2, 3, 4}\]

\begin{itemize}
\tightlist
\item
  5 on 1: more data = more better?
\end{itemize}

\[ d \in D \]

This results \((5+5+1)*5\) sets of hyperparameters.

\hypertarget{stage-2-simulation-1}{%
\section{Stage 2: simulation}\label{stage-2-simulation-1}}

for every for every model (5), for every dataset (5) and for every set of optimized hyperparameters (3), a simulation study is performed. From these \(5*5*3=75\) simulation studies, performance of the different models is evaluated.

\hypertarget{outcomes}{%
\subsection{Outcomes}\label{outcomes}}

Several metrics are used to compare performance of different models over datasets,

\begin{longtable}[]{@{}lllllll@{}}
\toprule
\begin{minipage}[b]{0.29\columnwidth}\raggedright
Dataset\strut
\end{minipage} & \begin{minipage}[b]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Naive Bayes\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Random Forests\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Support Vector Machine\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Logistic Regression\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Dense Neural Network\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.29\columnwidth}\raggedright
ptsd\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
?\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
ace\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
?\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
hall\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
?\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
nagtegaal\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
?\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\ldots.\strut
\end{minipage} & \begin{minipage}[t]{0.03\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
?\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

? How to compare outcomes of 3 different optimization strategies?

\hypertarget{evaluation}{%
\section{Evaluation}\label{evaluation}}

\hypertarget{my-first-simulation}{%
\chapter{My first simulation}\label{my-first-simulation}}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

A simulation study was performed on the Nagtegaal dataset, using a model with the following configurations:

\begin{itemize}
\tightlist
\item
  Model = Naive Bayes
\item
  Query Strategy = max\_random
\item
  Balance Strategy = Double
\item
  n\_instances=10 (number of papers each query)
\item
  n\_papers=2000 (shouldn't I do all?)
\item
  n\_prior\_included = 5
\item
  n\_prior\_excluded = 5
\item
  mix\_ratio = 0.95 (95\% max, 5\% random)
\end{itemize}

\begin{longtable}[]{@{}lllll@{}}
\toprule
Hyperparameters & & default & optimized &\tabularnewline
\midrule
\endhead
Model & & & &\tabularnewline
& alpha & 3.822 & 3.511844 &\tabularnewline
Balance & & & &\tabularnewline
& a & 2.155 & 0.254892 &\tabularnewline
& alpha & 0.94 & 1.459081 &\tabularnewline
& b & 0.789 & 0.394437 &\tabularnewline
Feature & & & &\tabularnewline
& ngram\_max & 1 & 2 &\tabularnewline
& split\_ta & 0 & 1 &\tabularnewline
\bottomrule
\end{longtable}

For the sake of evaluating the optimized hyperparameters, two simulations of five runs each were compared: one with default hyperparameters and with optimized hyperparameters.

\hypertarget{results}{%
\section{Results}\label{results}}

Explanation of the plots come from the \texttt{asreview-visualization} repository.
The optimized hyperparameters do not perform better than the default ones, this is probably due to the fact that the default hyperparameters have already been optimized in the past. It is therefore to know for which models this has already been done and which not!

\pagebreak

\hypertarget{inclusions}{%
\subsubsection{Inclusions}\label{inclusions}}

This figure shows the number/percentage of included papers found as a function of the
number/percentage of papers reviewed. Initial included/excluded papers are subtracted so that the line
always starts at (0,0).

The quicker the line goes to a 100\%, the better the performance.

\includegraphics[width=17.78in]{figs/myfirstsim/Figure_1}

In the beginning, the model with default parameters finds inclusions quicker than the model with optimized hyperparamters.
Only after reviewing 50\% of the papers, the optimized hyperparameters outperform the default ones.

\pagebreak

\hypertarget{discovery}{%
\subsubsection{Discovery}\label{discovery}}

This figure shows the distribution of the number of papers that have to be read before discovering
each inclusion. Not every paper is equally hard to find.

The closer to the left, the better.

\includegraphics[width=17.78in]{figs/myfirstsim/Figure_2}

\pagebreak

\hypertarget{limits}{%
\subsubsection{Limits}\label{limits}}

This figure shows how many papers need to be read with a given criterion. A criterion is expressed
as ``after reading \emph{y} \% of the papers, at most an average of \emph{z} included papers have been not been
seen by the reviewer, if he is using max sampling.''. Here, \emph{y} is shown on the y-axis, while
three values of \emph{z} are plotted as three different lines with the same color. The three values for
\emph{z} are 0.1, 0.5 and 2.0.

The quicker the lines touch the black (\texttt{y=x}) line, the better.

\includegraphics[width=17.78in]{figs/myfirstsim/Figure_3}

\pagebreak

\hypertarget{console-output}{%
\section{Console output}\label{console-output}}

3120 iterations ran overnight.

\includegraphics[width=26.42in]{figs/myfirstsim/computation}
2191 was best performing with a loss of 0.1124

\includegraphics[width=23in]{figs/myfirstsim/optmizationresult}

\hypertarget{notes}{%
\section{Notes}\label{notes}}

\begin{itemize}
\item
  Optimizing the hyperparameters with the Nagtegaal set and then running a simulation on the Nagtegaal dataset is using the data twice.
  This leads to overfitting. A next approach could be to perform some way of cross-validation, e.g.~split the datasets in train and test datasets.
\item
  There are two main optimization modes: passive and active learning.
  The first is used here and is relatively fast, the second is more computationally expensive.
\item
  Of primary interest is the comparison of different model configurations in predictive performance.
  A simulation study can be performed with all possible configurations using the default hyperparameters.
  The results could be used to select model configurations that could possibly benefit from hyperparameter sreening.
\item
  Second, we could investigate how much is to gain in predictive performance from optimizing the hyperparameters.
  For this, some cross-validation strategy should be used.
  Optimization can consist of two steps:
  first, optimization through passive learning can be performed, from which the best performing models can be selected for the second step:
  optimization through passive learning.
\end{itemize}

\hypertarget{possible-research-questions}{%
\subsection{Possible Research Questions}\label{possible-research-questions}}

\begin{itemize}
\tightlist
\item
  Which model configurations have good predictive performance?

  \begin{itemize}
  \tightlist
  \item
    for what kind of data sets and under which circumstances?
  \end{itemize}
\item
  Does optimization of hyperparameters lead to substantial gain in predictive performance?

  \begin{itemize}
  \tightlist
  \item
    How much and why?
  \item
    How do the hyperparameters relate to one another?
  \item
    What is the optimal way to tune the hyperparameters?

    \begin{itemize}
    \tightlist
    \item
      to determine by cross-validation
    \item
      for example: optimize over a large number of datasets? or a different strategy?
    \end{itemize}
  \end{itemize}
\item
  \ldots{}
\item
  \ldots{}
\end{itemize}

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{list-of-definitions}{%
\chapter{List of definitions}\label{list-of-definitions}}

  \bibliography{book.bib,packages.bib}

\end{document}
