<?xml version="1.0" encoding="UTF-8"?>
<w:document xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math" xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:w10="urn:schemas-microsoft-com:office:word" xmlns:a="http://schemas.openxmlformats.org/drawingml/2006/main" xmlns:pic="http://schemas.openxmlformats.org/drawingml/2006/picture" xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing"><w:body><w:p><w:pPr><w:pStyle w:val="Title" /></w:pPr><w:r><w:t xml:space="preserve">Manuscript</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">drafts</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Author" /></w:pPr><w:r><w:t xml:space="preserve">Gerbrich</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Ferdinands</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Date" /></w:pPr><w:r><w:t xml:space="preserve">1/14/2020</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="20" w:name="introduction" /><w:r><w:t xml:space="preserve">Introduction</w:t></w:r><w:bookmarkEnd w:id="20" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="21" w:name="methods" /><w:r><w:t xml:space="preserve">Methods</w:t></w:r><w:bookmarkEnd w:id="21" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">A convenience sample of 5 existing systematic reviews on varying topics was collected.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="22" w:name="results" /><w:r><w:t xml:space="preserve">Results</w:t></w:r><w:bookmarkEnd w:id="22" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="23" w:name="discussion" /><w:r><w:t xml:space="preserve">Discussion</w:t></w:r><w:bookmarkEnd w:id="23" /></w:p><w:p><w:r><w:br w:type="page" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="24" w:name="introduction-1" /><w:r><w:t xml:space="preserve">Introduction</w:t></w:r><w:bookmarkEnd w:id="24" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Systematic Reviews (SR’s) are booming - but they are a lot of work</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Various machine learning tools have been proposed to reduce workload in abstract screening.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">objectives - to demonstrate effectiveness of ml algorithm in reducing abstract classification for systematic reviews</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">justification -</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">background</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">guidance to reader</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">summary/conclusion</w:t></w:r></w:p><w:p><w:r><w:pict><v:rect style="width:0;height:1.5pt" o:hralign="center" o:hrstd="t" o:hr="t" /></w:pict></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">This study is about how machine learning algorithms can increase efficiency in systematic reviews. I will write about what SRs are, and how workload can be reduced.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Systematic reviews are top of the bill in research. As more and more papers are published and reproducibility crisis has emerged, science calls for more meta. It is important reflect on research by giving an overview of research areas which is typically done by a systematic review […]. Performing a systematic review is a tedious and time-consuming task. To review a specific research area, one starts out with an initial search of thousands of academic papers. All these papers abstracts need to be screened to find an initial batch of possibly relevant papers. With now hopefully only a couple of hundred papers left, the researcher needs to read these papers full-text to arrive at a final selection of papers that are relevant for the final systematic review [this is prisma process?]. This whole processes costs this and this much time [shelmilt].</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The stage of abstract screening where abstracts are systematically screened is where a lot is to be gained. This stage is the target of possible learning algorithms that can assist the reviewer in selecting the relevant papers. Together with the reviewer /human machine interaction. The algorithm aims to compute which papers in the pool need to be excluded and which need to be included, based on the reviewers decisions. It learns from the reviewers decisions and asks the reviewer to provide more labels, incrementally improving its class predictions.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The goal of the algorithm defined in the current study is to reduce to number of abstracts needed to screen (maybe not right term, bit biomedical). To be more specific, the algorithm aims to present the reader with the primary studies as soon as possible. This means that at some point you probably have seen all relevant abstracts and are only viewing excluded papers, which means you can stop reviewing much earlier (theoretically spoken). Also reviewing is now much more fun. As compared to when you have to review all abstracts and you perhaps see only one relevant abstract every other week/day.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">So you might wonder, how does such an algorithm actually work? Active learning strategy, starting with a pool of unlabeled abstracts (U). The reviewer starts labeling some instances in U, creating L. The algorithm utilizes L to predict labels for all abstracts (classifier), by using a set of features from the papers called X, for example the text in the abstract (feature extraction method). Now, it made an initial classification. The algorithm now aims to improve its classification by which paper from U will be presented to the reviewer next. By labeling the next paper, the reviewer provides the algorithm with new information which the algorithm uses to update its prediction.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">We approach asr as a classification problem:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">All papers obtained in the systematic search form a pool of instances x.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">All instances x need to be classified, e.g. we want to give them a label y.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">all x are now part of U,.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Binary classification, either inclusion or exclusion.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We want to classify based on some features from the instances</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>x</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">, feature vector</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="b" /></m:rPr><m:t>X</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">By starting of with L, the algorithm utilizes characteristics of X to predict labels in U.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">We want to classify the papers in</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Where the whole collection of papers in the systematic search form a pool of instances x, with unknown label y.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">&lt;x,y&gt;.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">input:  </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    a pool of unlabeled abstracts $\mathcal{U}$ </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    oracle labels a few initial papers, from $\mathcal{U}$, $\mathcal{L}$, </w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  M = train($\mathcal{L}$)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  Query x \isin \mathcal{U} (&lt;x, y=?)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  oracle &lt;x, y&gt;</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">  </w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">pool unlabeled abstracts</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="p" /><m:scr m:val="script" /></m:rPr><m:t>U</m:t></m:r></m:oMath></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">labeled data set</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="p" /><m:scr m:val="script" /></m:rPr><m:t>L</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">,</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">instance</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>x</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">, label</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>y</m:t></m:r></m:oMath></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">utility measure</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:sSub><m:e><m:r><m:t>ϕ</m:t></m:r></m:e><m:sub><m:r><m:t>A</m:t></m:r></m:sub></m:sSub><m:r><m:t>(</m:t></m:r><m:r><m:t>⋅</m:t></m:r><m:r><m:t>)</m:t></m:r></m:oMath></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><m:oMath><m:sSubSup><m:e><m:r><m:t>x</m:t></m:r></m:e><m:sub><m:r><m:t>A</m:t></m:r></m:sub><m:sup><m:r><m:t>*</m:t></m:r></m:sup></m:sSubSup></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">best query instance according to</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:sSub><m:e><m:r><m:t>ϕ</m:t></m:r></m:e><m:sub><m:r><m:t>A</m:t></m:r></m:sub></m:sSub><m:r><m:t>(</m:t></m:r><m:r><m:t>⋅</m:t></m:r><m:r><m:t>)</m:t></m:r></m:oMath></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Now there are a few technical details. Many different versions of such algorithms exist. Many of such algorithms have been described in the active learning literature and have been applied in the systematic reviewing process. Not exhaustive, but the algorithm can apply many different strategies to arrive at its predictions, which can be divided in following parameters: classifier, feature extraction strategy, balancing, query strateg y.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Most often the SVM classifier is used, popular and very good results. Also lots of other configurations. However, other classifiers have not been tested a lot (polygon thing by cohe, naïve bayes and random forest by …), but mostly SVM still. Also, most research in the medical sciences (well there are some exceptions of course [conversation between cohen and matwill]</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">In the current study, we aim at exploring the performance of several classifiers on reducing workload while maintaining performance in abstract screening process. This is done by performing simulations on existing systematic reviews. Performance is evaluated by how much time can be saved … while maintaining accuracy.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Present research questions.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">RQ1 – which classifiers perform best?</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">- RQ1a – does classifier performance vary over different research areas?</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(in what terms does it perform best)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">RQ2 different hyperparameter optimizations?</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Classifiers come with hyperparameters. We have to make a choice on how to set these hyperparameters. What we do is create 3 sets, optimizing in three ways, aggregate results obtained.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The goal is to gain insight in classifiers other than the widely applied SVM, overall various research areas.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">So not only medical sciences.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">To perform all these computations the research was carried out using the ASReview software by Utrecht University, which has a simulation mode that you can just input your labelled review file into and perform a simulation study with it. To be found on GitHub. It has many adjustable components/is very versatile.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Then if we still have time left we explore the effect of another feature extraction method, namely doc2vec. This might possibly increase performance as it performs better at grasping structure/hidden relations/hierarchy between words in the texts. So, it could be interesting in more</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">fuzzy</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">research areas. A downside is that it takes more computing time.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Then if there’s even more time we might want to compare a different balance strategy.</w:t></w:r></w:p><w:p><w:r><w:pict><v:rect style="width:0;height:1.5pt" o:hralign="center" o:hrstd="t" o:hr="t" /></w:pict></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">A SR can be divided into phases.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Everything starts with a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">systematic search</w:t></w:r><w:r><w:t xml:space="preserve">, leading to</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">then citation screening is performed, then full-text screening</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(PRISMA-P Group et al. 2015)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">What must be the objective of our tool?:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">It is the tedious task citation screening part where loads of time can be saved.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">models are designed in a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">realistic</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">way (you have some inclusions)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Selecting papers is a two-step process: abstract &amp; fulltext screening</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Binary classification problem.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">predict whether a paper in the pool is an inclusion or exclusion,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">based on labeled instances from</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="p" /><m:scr m:val="script" /></m:rPr><m:t>L</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and use training data to understand how input variables are related to class.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">We’re building active learning model who takes X as an input an predicts class using labels from training set.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Model improves by deciding asking more information from the reviewer (oracle),</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">accounting for imbalance.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The researcher has some prior knowledge about the pool, some papers ought to be included in the SR.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="25" w:name="assumptions" /><w:r><w:t xml:space="preserve">Assumptions</w:t></w:r><w:bookmarkEnd w:id="25" /></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">decisions of the original SR are</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">ground truth</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(benchmark) (oracle)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">The inclusion rate is … data is imbalanced.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">what is the philosophy</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">False negatives must be avoided …</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The cost of a false negative outweighs the cost of a false positive.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Note that we assume the oracle/original user to hold the truth.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">This is of course not always the case.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">There are two classes in the data: exlusions and inclusions.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The inclusions are clearly the minority class.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Datasets from the medical and social sciences, software engineering and public administration.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Medical sciences SRs are viewed as more</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">strict</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve">/</w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">structured</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and social sciences more messy.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="26" w:name="active-learning-for-systematic-reviews" /><w:r><w:t xml:space="preserve">active learning for systematic reviews</w:t></w:r><w:bookmarkEnd w:id="26" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">corpus = all the text:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Active learning =</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">increasing classification performance with every query.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The query strategy determines the way unlabeled papers are queried to the researcher.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">(Danka and Horvath, n.d.)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">RQ1 - what are good classifiers</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">RQ2 - what are good optimization strategies</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="27" w:name="background" /><w:r><w:t xml:space="preserve">Background</w:t></w:r><w:bookmarkEnd w:id="27" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">(O’Mara-Eves et al. 2015)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">literature review</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">(Yu, Kraft, and Menzies 2018)</w:t></w:r><w:r><w:t xml:space="preserve">,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Yu and Menzies 2019)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">simulated 32 svm classifiers, on software engineering.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A popular classifier is SVM. succes with HUTM (fastread), uncertainty, mix of weighting and agressive undersampling,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">In terms of Yu et al, we adopt .CT.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">SVM - tf-idf on medical data, uncertainty sampling, agressive undersampling.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Wallace et al. 2010)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">abstrackr</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">SVM + Weighting + uncertainty (bow) produced good methods</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Miwa et al. 2014)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Also include social sciences data besides medical data.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">(Cohen et al. 2006)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">perceptron-based classifier (neural network)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">SVM on legal documents (no balancing, certainty )</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Cormack and Grossman 2014)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">in limitations section mentions that LR yields about same results, nb inferior results.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">(Kilicoglu et al. 2009)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">- SVM, naive bayes, boosting and combinations. future work should optimize parameters.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">“</w:t></w:r><w:r><w:t xml:space="preserve">Regarding the base classifiers used in identifying method- ologically rigorous studies, boosting consistently strikes the best balance between precision and recall, whereas naive Bayes in general performs well on recall (demonstrating a tradeoff between recall and precision), as does polynomial SVM on precision. The AUC results are mixed, although boosting has a slight edge overall. These results demonstrate that different classifiers can be used to satisfy different information needs (SVM for specificity, naive Bayes for sensitivity, and boosting for balance between the two, for example).</w:t></w:r><w:r><w:t xml:space="preserve">”</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Our extensions is that we try different classifiers, on more datasets.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">This study was approved by the Ethics Committee of the Faculty of Social and Behavioural Sciences of Utrecht University, filed as an amendement under study 20-104.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">All simulations were run using through cartesius EINF-156</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Goal: evaluate performance of different models of the ASReview tool.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The screening process is simulated using ASReview, seeing if the original inclusions replicate.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">What would happen if the citation screening would have been performed using asreview?</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">All datasets accompanying the systematic reviews are openly published.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We built several machine learning models to perform automated systematic reviews,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">who are then applied on existing systematic reviews.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">When no balancing is applied, the training data set = labeled data set</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="p" /><m:scr m:val="script" /></m:rPr><m:t>L</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The model can query the labels, who serve as the reviewer, active learning then perform active learning to detect inclusions.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">a machine learning-based citation classification tool to reduce workload in systematic reviews of drug class efficacy.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Using a perceptron classifier,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId28"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">WSS@95</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">% = 56.61 in</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Cohen et al. 2006)</w:t></w:r><w:r><w:t xml:space="preserve">. (5x2 crossvalidation). Can we beat this?</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The data</w:t></w:r></w:p><w:p><w:r><w:br w:type="page" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="29" w:name="methods-1" /><w:r><w:t xml:space="preserve">Methods</w:t></w:r><w:bookmarkEnd w:id="29" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Performance of several machine learning models was demonstrated on six systematic review datasets.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="30" w:name="models" /><w:r><w:t xml:space="preserve">Models</w:t></w:r><w:bookmarkEnd w:id="30" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">x</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">machine learning models (</w:t></w:r><m:oMath><m:r><m:t>M</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">) were built.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The models consist of multiple components, of which the classifier and the feature extraction strategy varied over the models.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="31" w:name="classifiers" /><w:r><w:t xml:space="preserve">Classifiers</w:t></w:r><w:bookmarkEnd w:id="31" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Every model applies a classifier</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>c</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">to predict the relevance of publications in the data.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The classfiier predicts the class of a publication in the dataset expediting a training dataset</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="p" /><m:scr m:val="script" /></m:rPr><m:t>L</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">predicts the class of an instance given input features</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="b" /></m:rPr><m:t>X</m:t></m:r></m:oMath></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Logistic Regression (LR) - L2-regularized logistic regression.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Logistic models the posterior directly, naive bayes has higher bias but lower variance,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">logistic might perform better when trainign set increases.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Ng and Jordan 2002)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Naive Bayes (NB) - Naive Bayes assumes all features are independent given the class value. This is obviously not the case but still the algorithm performs impressively</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Zhang 2004)</w:t></w:r><w:r><w:t xml:space="preserve">. Especially at … tasks.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Random Forests (RF) is where a large number of decision trees are fit on bootstrapped samples of the original data. All trees cast a vote on the class, which are aggregated into a class prediction for each input</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:rPr><m:sty m:val="b" /></m:rPr><m:t>X</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Breiman 2001)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Support Vecor Machine (SVM) - finds a multidimensional hyperplane to separate classes.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Tong and Koller 2001)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="32" w:name="word-representation" /><w:r><w:t xml:space="preserve">Word representation</w:t></w:r><w:bookmarkEnd w:id="32" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">To predict the class of a publication class (e.g. whether a publication should be included or excluded), the classifier uses information from the publications in the dataset.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Examples of such information are titles and abstracts.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">However, the classifier cannot predict the publication class from titles and abstracts as they are.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Their textual content to needs to be mapped to feature vectors.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">This process of numerically representing textual content is called</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">word embeddings</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">A classical example of word embeddings a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">bag of words</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">representation.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">For each text in the data set, the number of occurrences of each word is stored.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">This leads to n features, where n is the number of distinct words in the texts</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Pedregosa et al. 2011)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The bag-of-words method is simplistic and will highly value often occuring but otherwise meaningless words such as</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">“</w:t></w:r><w:r><w:t xml:space="preserve">and</w:t></w:r><w:r><w:t xml:space="preserve">”</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Term-frequency Inverse Document Frequency (TF-IDF)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Ramos and others 2003)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">circumvents this problem by adjusting a term frequency in a text with the inverse docuement frequency, the frequency of a given word in the entire data set.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The model expedits features of previously labeled publications and</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Based on features of the previously labeled inclusions and exclusions, the model</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The features used are title and abstract from every publication. - this is what is prescribed by prisma, (check!)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">(TF-IDF) (Doc2Vec)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="33" w:name="fixed-components" /><w:r><w:t xml:space="preserve">Fixed components</w:t></w:r><w:bookmarkEnd w:id="33" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">All models</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>M</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">apply the same query strategy of certainty sampling, in which the presented publication is always the one of which the model is most certain for it to be relevant.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">To decrease the class imbalance in the training data, the model rebalances the training set by Dynamic Supersampling (DS). DS decreases the number of irrelevant papers in the training data, whereas the number of relevant papers are increased (by copy) such that the total number of samples remains the same. The ratio between relevant and irrelevant papers is not fixed, but dynamically updated and depends on the number of training samples, the total number of publications and the ratio between relevant and irrelevant publications.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="34" w:name="datasets" /><w:r><w:t xml:space="preserve">Datasets</w:t></w:r><w:bookmarkEnd w:id="34" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Six Systematic Reviews from various research areas were used to simulate the automated systematic review process. Data were preprocessed from the original source into a test dataset, containing all publications obtained in the systematic search. The test datasets are labelled indicating the relevant and irrelevant publications. Using these labels, a computer simulation of an automated systematic review can be performed on the systematic review data.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The test datasets contain title information on all publications obtained in the search strategy.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The instances in the data consist of a title and an abstract and were labeled to indicate which publications were included in the systematic review. Instances with missing abstracts and duplicate instances were removed from the data. The data preprocessing scripts can be found on the GitHub</w:t></w:r><w:r><w:rPr><w:rStyle w:val="FootnoteReference" /></w:rPr><w:footnoteReference w:id="35" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Cohen et al. collected systematic review datasets from the medical sciences</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Cohen et al. 2006)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">All systematic reviews in this database are on drug efficacy. The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">ace</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">dataset used in the current study comes from a systematic review on the efficacy of Angiotensin-converting enzyme (ACE) inhibitors.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">software</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">dataset is retrieved from</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Yu, Kraft, and Menzies 2018)</w:t></w:r><w:r><w:t xml:space="preserve">, who collected datasets on literature reviews from the software engineering field. This dataset is on fault prediction in software engineering by</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Hall et al. 2012)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">nudging</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">dataset comes from a review from the behavioural public administration area. The SR includes studies on nudging healthcare professionals</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Nagtegaal et al. 2019a)</w:t></w:r><w:r><w:t xml:space="preserve">. The data was stored on the Harvard Dataverse</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Nagtegaal et al. 2019b)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">A literature review from field of psychology,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">ptsd</w:t></w:r><w:r><w:t xml:space="preserve">. The SR is on studies applying latent trajectory analyses on posttraumatic stress after exposure to trauma</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(</w:t></w:r><w:r><w:t xml:space="preserve">van de Schoot et al. 2017)</w:t></w:r><w:r><w:t xml:space="preserve">. The corresponding data can be found on the Open Science Framework […].</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">wilson</w:t></w:r><w:r><w:t xml:space="preserve">, a dataset from the medical sciences</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Appenzeller-Herzog 2020)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">TA review on effectiveness treatments of Wilson disease</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Appenzeller-Herzog et al. 2019)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">All datasets started with an initial pool of thousands of papers.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A fraction of these papers where deemed relevant for the SR, with inclusion rates around 1-2 percent with one outlier of about 5 percent (Table 1).</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Table 1: Statistics on datasets from original systematic reviews.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="37" w:name="optimizing-hyperparameters" /><w:r><w:t xml:space="preserve">Optimizing hyperparameters</w:t></w:r><w:bookmarkEnd w:id="37" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Every model component contains hyperparameters, leading to a unique set of hyperparameters for each model. To maximize model performance, we need to find optimal values for the hyperparameters.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">For every model the optimal hyperparameter values are determined by optimizing on the data</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The hyperparameters are optimized by running several hundreds of optimization trials, in which hyperparameter values are sampled from their possible parameter space.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A description of all hyperparameters and their sample space can be found in the appendix.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Maximum model performance is defined as the average time it takes to find an inclusion in the data, or more specific: the loss function minimizes the average number of papers needed to screen to find an inclusion (e.g. the area above the curve in the inclusion plot).</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The optimization data</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">consists of (a subset from) the six systematic review datasets</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>D</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">mentioned above.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Three different approaches in composing</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">are explored:</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">one</w:t></w:r><w:r><w:t xml:space="preserve">, where hyperparameters are optimized on only one of the six datasets,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r><m:r><m:t>∈</m:t></m:r><m:r><m:t>D</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">. Such hyperparameters are expected to lead to maximum performance in the same dataset</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">n</w:t></w:r><w:r><w:t xml:space="preserve">, where hyperparameters are optimized on all six data sets,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r><m:r><m:t>=</m:t></m:r><m:r><m:t>D</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">. This optimization approach intends to serve in producing the most optimal hyperparameters overall.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">n-1</w:t></w:r><w:r><w:t xml:space="preserve">, where hyperparameters are optimized on all six datasets but one,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>d</m:t></m:r><m:r><m:t>⊂</m:t></m:r><m:r><m:t>D</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">. Serving as a sensitivity analysis for the former condition, e.g. how sensitive are the hyperparamters. also as a cross-validation later on: hyperparameters obtained by training data, test data is never seen before.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">where d are all datasets but the one where we want to simulate later on.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">This results in</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>6</m:t></m:r><m:r><m:t>+</m:t></m:r><m:r><m:t>6</m:t></m:r><m:r><m:t>+</m:t></m:r><m:r><m:t>1</m:t></m:r><m:r><m:t>=</m:t></m:r><m:r><m:t>13</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">sets of hyperparameters for every model.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Results were visually inspected to check if an optimum (minimal loss) has been reached.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">More trials were run if the loss still seemed to go down at a quick pace.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The hyperparameter values that were found to lead to a minimum loss value were visually inspected.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="38" w:name="optimization-results" /><w:r><w:t xml:space="preserve">Optimization results</w:t></w:r><w:bookmarkEnd w:id="38" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">For every model, 13 sets of hyperparameters were optimized.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">to include: plotting the loss reduction over trials</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Optimal values of the hyperparameters were visually inspected.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">As an example, the hyperparameters of the RF_TF-IDF model are presented in Figure 1.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A panel displays the optimal values for a certain hyperparameter, where the blue colored dots represent the</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">one</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">condition, the green dots the</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">n-1</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">condition and the orange dot represents the optimal hyperparameter value when optmizing over all datasets (</w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">n</w:t></w:r><w:r><w:t xml:space="preserve">). The x-axis represents the possible parameter space where the vertical grey lines mark the boundaries of the hyperparameter space (if possible). Note that the feature parameters ngram_max, split_ta, use_keywords and model parameters max_features and n_estimators are categorical.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Overall, the optimal values are distributed over the parameter space. Outlying values all belong to the</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">one</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">condition where optimization was dependent on one dataset only. Fore example, the class_weight parameter has an outlying value of 11.3 that belongs to the nudging dataset. (Why this is the case I can only speculate, but it is worth mentioning that this dataset has a relatively high inclusion rate of 5.41%, compared to the other datasets).</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:drawing><wp:inline><wp:extent cx="5334000" cy="6035237" /><wp:effectExtent b="0" l="0" r="0" t="0" /><wp:docPr descr="" title="" id="1" name="Picture" /><a:graphic><a:graphicData uri="http://schemas.openxmlformats.org/drawingml/2006/picture"><pic:pic><pic:nvPicPr><pic:cNvPr descr="figs/rf_tfidf.eps" id="0" name="Picture" /><pic:cNvPicPr><a:picLocks noChangeArrowheads="1" noChangeAspect="1" /></pic:cNvPicPr></pic:nvPicPr><pic:blipFill><a:blip r:embed="rId39" /><a:stretch><a:fillRect /></a:stretch></pic:blipFill><pic:spPr bwMode="auto"><a:xfrm><a:off x="0" y="0" /><a:ext cx="5334000" cy="6035237" /></a:xfrm><a:prstGeom prst="rect"><a:avLst /></a:prstGeom><a:noFill /><a:ln w="9525"><a:noFill /><a:headEnd /><a:tailEnd /></a:ln></pic:spPr></pic:pic></a:graphicData></a:graphic></wp:inline></w:drawing></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="40" w:name="Xebac7019d2795fb9bac5aead381dca860b154a5" /><w:r><w:t xml:space="preserve">Appendix x - Hyperparameters and their sample space</w:t></w:r><w:bookmarkEnd w:id="40" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Classifier hyperparameters</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">class_weight: normal(0,1) constrained to be &gt; 0</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">class weight of the inclusions.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">                 </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Logistic Regression</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">c: float. normal(0,1), constrained to be &gt; 0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Support Vector Machine</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">gamma: [&quot;auto&quot;, &quot;scale&quot;],</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">Gamma parameter of the SVM model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">C: </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">C parameter of the SVM model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">kernel:</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">SVM kernel type.[&quot;linear&quot;, &quot;rbf&quot;, &quot;poly&quot;, &quot;sigmoid&quot;]</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Naive Bayes</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">&quot;model_param.alpha&quot;, # exp(normal(0,1))</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">         </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Random Forest</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">max_features: int (between 6 and 10)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Number of features in the model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">n_estimators: int between 10 and 100 </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Number of estimators.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">model_param.n_estimators&quot; #quniform(10,100,1)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Balance strategy hyperparameters:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Dynamic supersampling:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">a: float</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Governs the weight of the 1&#39;s. Higher values mean linearly more 1&#39;s</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    in your training sample.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">alpha: float</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Governs the scaling the weight of the 1&#39;s, as a function of the</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    ratio of ones to zeros. A positive value means that the lower the</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    ratio of zeros to ones, the higher the weight of the ones.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">b: float</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Governs how strongly we want to sample depending on the total</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    number of samples. A value of 1 means no dependence on the total</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    number of samples, while lower values mean increasingly stronger</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    dependence on the number of samples.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Feature extraction strategy hyperparameters</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">split_ta: 0 or 1</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">   whether titles and abstracts are split </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">   </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">use_keywords: 0 or 1</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    whether keywords should be used</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">   </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">TF-IDF</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">ngram_max: 1, 2 or 3</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Can use up to ngrams up to ngram_max. For example in the case of </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    ngram_max=2, monograms and bigrams could be used.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Doc2Vec</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">vector_size: int (between 32 and 127)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Output size of the vector.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">epochs: int (between 20 and 50)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Number of epochs to train the doc2vec model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">min_count: int (between 1 and 3)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Minimum number of occurences for a word in the corpus for it to be </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    included in the model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">window: int (between 5 and 9)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Maximum distance over which word vectors influence each other.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">dm_concat: int 0 or 1</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Whether to concatenate word vectors or not.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">                 </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">dm: int </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Model to use.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    0: Use distribute bag of words (DBOW).</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    1: Use distributed memory (DM).</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    2: Use both of the above with half the vector size and concatenate them.</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">dbow_words: int 0 or 1</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    Whether to train the word vectors using the skipgram method.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="41" w:name="simulations" /><w:r><w:t xml:space="preserve">Simulations</w:t></w:r><w:bookmarkEnd w:id="41" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">To demonstrate the models, simulations are performed of the models on six original systematic reviews.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">With the labeled datasets, the systematic review can be reproduced but with now using a machine learning model to optimize the reviewing process.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The initial training set of the active learning model in the simulation is one prior included publication and one prior excluded publication, randomly sampled from the data.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">This demonstrates a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">‘</w:t></w:r><w:r><w:t xml:space="preserve">worst case scenario</w:t></w:r><w:r><w:t xml:space="preserve">’</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">where the reviewer has minimal prior knowledge on publications in the data.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">For this simulations there is no need for a human reviewer since the labels in the data can be queried.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The oracle is not the reviewer but the labels in the data.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The model retrains every time after a label is provided by the oracle.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The simulation ends when all publications in the dataset have been queried.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">To account for variance, every simulation is repeated for 15 trials</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>t</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="42" w:name="statistical-analysis" /><w:r><w:t xml:space="preserve">Statistical analysis</w:t></w:r><w:bookmarkEnd w:id="42" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Results are aggregated over 15 runs of every simulation.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="43" w:name="measures" /><w:r><w:t xml:space="preserve">measures</w:t></w:r><w:bookmarkEnd w:id="43" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="44" w:name="comparison-over-conditions" /><w:r><w:t xml:space="preserve">comparison over conditions</w:t></w:r><w:bookmarkEnd w:id="44" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="45" w:name="the-software" /><w:r><w:t xml:space="preserve">The software</w:t></w:r><w:bookmarkEnd w:id="45" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">ASReview takes the following parameters/arguments:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We now have 75 combinations.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">for every for every model (5), for every dataset (5) and for every set of optimized hyperparameters (3), a simulation study consisting trials is performed. From these</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><m:oMath><m:r><m:t>5</m:t></m:r><m:r><m:t>*</m:t></m:r><m:r><m:t>5</m:t></m:r><m:r><m:t>*</m:t></m:r><m:r><m:t>3</m:t></m:r><m:r><m:t>=</m:t></m:r><m:r><m:t>75</m:t></m:r></m:oMath><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">simulation studies, performance of the different models is evaluated.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Use these inputs to predict relevance of papers.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="46" w:name="stage-1-hyperparameter-optimization" /><w:r><w:t xml:space="preserve">Stage 1: hyperparameter optimization</w:t></w:r><w:bookmarkEnd w:id="46" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Or, more specific:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="47" w:name="performance-metrics" /><w:r><w:t xml:space="preserve">Performance metrics</w:t></w:r><w:bookmarkEnd w:id="47" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">For each model,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Several metrics are used to compare performance of different models over datasets,</w:t></w:r></w:p><w:tbl><w:tblPr><w:tblStyle w:val="Table" /><w:tblW w:type="pct" w:w="5000.0" /><w:tblLook w:firstRow="1" /></w:tblPr><w:tblGrid><w:gridCol w:w="2851" /><w:gridCol w:w="316" /><w:gridCol w:w="950" /><w:gridCol w:w="950" /><w:gridCol w:w="950" /><w:gridCol w:w="950" /><w:gridCol w:w="950" /></w:tblGrid><w:tr><w:trPr><w:cnfStyle w:firstRow="1" /></w:trPr><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Dataset</w:t></w:r></w:p></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p /></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Naive Bayes</w:t></w:r></w:p></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Random Forests</w:t></w:r></w:p></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Support Vector Machine</w:t></w:r></w:p></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Logistic Regression</w:t></w:r></w:p></w:tc><w:tc><w:tcPr><w:tcBorders><w:bottom w:val="single" /></w:tcBorders><w:vAlign w:val="bottom" /></w:tcPr><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">Dense Neural Network</w:t></w:r></w:p></w:tc></w:tr><w:tr><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">ptsd</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">?</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc></w:tr><w:tr><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">ace</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">?</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc></w:tr><w:tr><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">hall</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">?</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc></w:tr><w:tr><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">nagtegaal</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">?</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc></w:tr><w:tr><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">….</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p><w:pPr><w:pStyle w:val="Compact" /><w:jc w:val="left" /></w:pPr><w:r><w:t xml:space="preserve">?</w:t></w:r></w:p></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc><w:tc><w:p /></w:tc></w:tr></w:tbl><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">The goal is twofold: we want to identify all relevant papers, as fast as we can.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Tradeoff: identifying all relevant papers and reducing workload.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A good metric to evaluate this is..</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">What is more important: recall or precision?</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Recall more highly valued than precision.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">What about class imbalance?</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="48" w:name="rrf" /><w:r><w:t xml:space="preserve">RRF</w:t></w:r><w:bookmarkEnd w:id="48" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Amount of relevant references found after having screened a certain percentage of the total number of abstracts.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="49" w:name="work-saved-over-sampling-wss" /><w:r><w:t xml:space="preserve">Work saved over sampling (WSS)</w:t></w:r><w:bookmarkEnd w:id="49" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Indicates how much time can be saved, at a given level of recall.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">WSS is in terms of the percentage of abstracts that don’t have to be screened by the researcher.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Typically, WSS is measured at a recall of 0.95. Reasonable because..</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><m:oMathPara><m:oMathParaPr><m:jc m:val="center" /></m:oMathParaPr><m:oMath><m:r><m:rPr><m:nor /><m:sty m:val="p" /><m:scr m:val="monospace" /></m:rPr><m:t>WSS</m:t></m:r><m:r><m:t>=</m:t></m:r><m:f><m:fPr><m:type m:val="bar" /></m:fPr><m:num><m:r><m:t>T</m:t></m:r><m:r><m:t>N</m:t></m:r><m:r><m:t>+</m:t></m:r><m:r><m:t>F</m:t></m:r><m:r><m:t>N</m:t></m:r></m:num><m:den><m:r><m:t>N</m:t></m:r></m:den></m:f><m:r><m:t>−</m:t></m:r><m:r><m:t>(</m:t></m:r><m:r><m:t>1</m:t></m:r><m:r><m:t>−</m:t></m:r><m:r><m:t>r</m:t></m:r><m:r><m:t>e</m:t></m:r><m:r><m:t>c</m:t></m:r><m:r><m:t>a</m:t></m:r><m:r><m:t>l</m:t></m:r><m:r><m:t>l</m:t></m:r><m:r><m:t>)</m:t></m:r></m:oMath></m:oMathPara></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="50" w:name="raoul" /><w:r><w:t xml:space="preserve">Raoul</w:t></w:r><w:bookmarkEnd w:id="50" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="51" w:name="utility" /><w:r><w:t xml:space="preserve">Utility?</w:t></w:r><w:bookmarkEnd w:id="51" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="52" w:name="f-measure" /><w:r><w:t xml:space="preserve">F-measure</w:t></w:r><w:bookmarkEnd w:id="52" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="53" w:name="rocauc" /><w:r><w:t xml:space="preserve">ROC/AUC</w:t></w:r><w:bookmarkEnd w:id="53" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Is performance related to some characteristic (n, inclusion rate, …)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">? How to compare outcomes of 3 different optimization strategies?</w:t></w:r></w:p><w:p><w:r><w:br w:type="page" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="54" w:name="results-1" /><w:r><w:t xml:space="preserve">Results</w:t></w:r><w:bookmarkEnd w:id="54" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">ace</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">nudging</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">ptsd</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">software</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">virus</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">wilson</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">BCTD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">RCTD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">SCTD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">LCTD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">NCTD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">BCDD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">RCDD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">SCDD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">LCDD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">NCDD</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">0</w:t></w:r></w:p><w:p><w:r><w:br w:type="page" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="55" w:name="discussion-1" /><w:r><w:t xml:space="preserve">Discussion</w:t></w:r><w:bookmarkEnd w:id="55" /></w:p><w:p><w:r><w:br w:type="page" /></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="56" w:name="appendix-a---list-of-definitions" /><w:r><w:t xml:space="preserve">Appendix A - list of definitions</w:t></w:r><w:bookmarkEnd w:id="56" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="57" w:name="feature-extraction-strategies" /><w:r><w:t xml:space="preserve">Feature Extraction Strategies</w:t></w:r><w:bookmarkEnd w:id="57" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">split_ta = overall hyperparameter</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="58" w:name="tf-idf" /><w:r><w:t xml:space="preserve">TF-IDF</w:t></w:r><w:bookmarkEnd w:id="58" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading5" /></w:pPr><w:bookmarkStart w:id="59" w:name="hyperparameters" /><w:r><w:t xml:space="preserve">hyperparameters</w:t></w:r><w:bookmarkEnd w:id="59" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">ngram_max: int</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Can use up to ngrams up to ngram_max. For example in the case of</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">ngram_max=2, monograms and bigrams could be used.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="60" w:name="doc2vec" /><w:r><w:t xml:space="preserve">Doc2Vec</w:t></w:r><w:bookmarkEnd w:id="60" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Predicts words from context.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Aims at capturing the relations between word (man-woman, king-queen).</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Le and Mikolov 2014)</w:t></w:r><w:r><w:t xml:space="preserve">. Using a neural network.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">using Continuous Bag-of-Words (CBOW), Skip-Gram model, ….</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Word vector</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">W</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and extra: document vector</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">D</w:t></w:r><w:r><w:t xml:space="preserve">, trained to predict words in the text.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">From gensim</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Řehůřek and Sojka 2010)</w:t></w:r><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve"> Arguments</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    ---------</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    vector_size: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Output size of the vector.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    epochs: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Number of epochs to train the doc2vec model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    min_count: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Minimum number of occurences for a word in the corpus for it to</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        be included in the model.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    workers: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Number of threads to train the model with.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    window: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Maximum distance over which word vectors influence each other.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    dm_concat: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Whether to concatenate word vectors or not.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        See paper for more detail.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    dm: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Model to use.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        0: Use distribute bag of words (DBOW).</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        1: Use distributed memory (DM).</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        2: Use both of the above with half the vector size and concatenate</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        them.</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    dbow_words: int</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        Whether to train the word vectors using the skipgram metho</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        </w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="61" w:name="sbert" /><w:r><w:t xml:space="preserve">SBERT</w:t></w:r><w:bookmarkEnd w:id="61" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">BERT-base model with mean-tokens pooling</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Reimers and Gurevych 2019)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="62" w:name="embeddingidf" /><w:r><w:t xml:space="preserve">embeddingIdf</w:t></w:r><w:bookmarkEnd w:id="62" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">This model averages the weighted word vectors of all the words in the text,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">in order to get a single feature vector for each text. The weights are provided by the inverse document frequencies</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="63" w:name="models-1" /><w:r><w:t xml:space="preserve">Models</w:t></w:r><w:bookmarkEnd w:id="63" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="64" w:name="naive-bayes" /><w:r><w:t xml:space="preserve">Naive Bayes</w:t></w:r><w:bookmarkEnd w:id="64" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Naive Bayes assumes all features are independent given the class value.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Zhang 2004)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">ASReview uses the</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">MultinomialNB</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">from the scikit-learn package</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Pedregosa et al. 2011)</w:t></w:r><w:r><w:t xml:space="preserve">, that implements the naive Bayes algorithm for multinomially distributed data.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">nb</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Hyperparameters</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">alpha - accounts for features not present in learning samples and prevents zero probabilities in further computations.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="65" w:name="random-forests" /><w:r><w:t xml:space="preserve">Random Forests</w:t></w:r><w:bookmarkEnd w:id="65" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">A number of decision trees are fit on bootstrapped samples of the original data,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Breiman 2001)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">RandomForestClassifier from sklearn</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Arguments</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">———</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">n_estimators: int</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Number of estimators.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">max_features: int</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Number of features in the model.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">class_weight: float</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Class weight of the inclusions.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">random_state: int, RandomState</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Set the random state of the RNG.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">&quot;&quot;&quot;</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="66" w:name="support-vector-machine" /><w:r><w:t xml:space="preserve">Support Vector Machine</w:t></w:r><w:bookmarkEnd w:id="66" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Arguments</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">———</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">gamma: str</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Gamma parameter of the SVM model.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">class_weight:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">class_weight of the inclusions.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">C:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">C parameter of the SVM model.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">kernel:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">SVM kernel type.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">random_state:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">State of the RNG.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="67" w:name="logistic-regression" /><w:r><w:t xml:space="preserve">Logistic Regression</w:t></w:r><w:bookmarkEnd w:id="67" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading4" /></w:pPr><w:bookmarkStart w:id="68" w:name="dense-neural-network" /><w:r><w:rPr><w:b /></w:rPr><w:t xml:space="preserve">Dense Neural Network</w:t></w:r><w:bookmarkEnd w:id="68" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="69" w:name="query-strategies" /><w:r><w:t xml:space="preserve">Query Strategies</w:t></w:r><w:bookmarkEnd w:id="69" /></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">Max - Choose the most likely samples to be included according to the model</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">Uncertainty - choose the most uncertain samples according to the model (i.e. closest to 0.5 probability)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Lewis and Catlett 1994)</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">Random - randomly selects abstracts with no regard to model assigned probabilities.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">Cluster - Use clustering after feature extraction on the dataset. Then the highest probabilities within random clusters are sampled</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">The following combinations are simulated:</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">cluster</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">max</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">cluster * random</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">cluster * uncertainty</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">max * cluster</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">max * random</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">max * uncertainty</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="70" w:name="balance-strategies" /><w:r><w:t xml:space="preserve">Balance Strategies</w:t></w:r><w:bookmarkEnd w:id="70" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading3" /></w:pPr><w:bookmarkStart w:id="71" w:name="amount-of-training-data" /><w:r><w:t xml:space="preserve">amount of training data</w:t></w:r><w:bookmarkEnd w:id="71" /></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1008" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">n_instances = number of papers queried each query</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1008" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">n_queries = number of queries</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1008" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">n_prior_included: 5</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1008" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">n_prior_excluded:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="72" w:name="combinations" /><w:r><w:t xml:space="preserve">Combinations</w:t></w:r><w:bookmarkEnd w:id="72" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">This leads to 119 combinations of configurations.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1009" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">Naive bayes only goes with tfidf feature extraction.</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1009" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">For the feature extraction strategies we will focus on doc2vec and tfidf. (but will compute all 4)</w:t></w:r></w:p><w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1009" /></w:numPr></w:pPr><w:r><w:t xml:space="preserve">This leads to 3 * 7 * 4 * 3 + 1 * 7 * 1 * 3 = 273 combinations.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">See appendix A for a table containing all 273 combinations.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:bookmarkStart w:id="73" w:name="cross-validation" /><w:r><w:t xml:space="preserve">Cross-validation</w:t></w:r><w:bookmarkEnd w:id="73" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Should give an accurate estimate of maximum performance / future systematic reviews to be performed.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="74" w:name="appendix-b---combinations" /><w:r><w:t xml:space="preserve">Appendix B - combinations</w:t></w:r><w:bookmarkEnd w:id="74" /></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="75" w:name="appendix-c---supercomputer-cartesius" /><w:r><w:t xml:space="preserve">Appendix C - supercomputer Cartesius</w:t></w:r><w:bookmarkEnd w:id="75" /></w:p><w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">500,000 SBU</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Running on Cartesius is charged in System Billing Units (SBUs), and charging is based on the wall clock time of a job. On fat and thin nodes, an SBU is equal to using 1 core for 1 hour (a core hour), or 1 core for 20 minutes on a GPU node. Since compute nodes are allocated exclusively to a single job at a time, you will be charged for all cores on that node - even if you are using less.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">In the current study, the classifier and the feature extraction strategy are varied, whereas the query and balance strategy remain fixed.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">In the current study only a fraction of all possible configurations are tested for the sake of brevity.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">There are many more options available and open to exploration.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:bookmarkStart w:id="76" w:name="references" /><w:r><w:t xml:space="preserve">References</w:t></w:r><w:bookmarkEnd w:id="76" /></w:p><w:bookmarkStart w:id="120" w:name="refs" /><w:bookmarkStart w:id="77" w:name="ref-Appenzeller-Herzog2020" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Appenzeller-Herzog, Christian. 2020. “Data from Comparative Effectiveness of Common Therapies for Wilson Disease: A Systematic Review and Meta-Analysis of Controlled Studies.” Zenodo.</w:t></w:r></w:p><w:bookmarkEnd w:id="77" /><w:bookmarkStart w:id="79" w:name="ref-Appenzeller-Herzog2019" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Appenzeller-Herzog, Christian, Tim Mathes, Marlies L. S. Heeres, Karl Heinz Weiss, Roderick H. J. Houwen, and Hannah Ewald. 2019. “Comparative Effectiveness of Common Therapies for Wilson Disease: A Systematic Review and Meta-Analysis of Controlled Studies.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Liver International</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">39 (11): 2136–52.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId78"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1111/liv.14179</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="79" /><w:bookmarkStart w:id="81" w:name="ref-Breiman2001" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Breiman, Leo. 2001. “Random Forests.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Machine Learning</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">45 (1): 5–32.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId80"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1023/A:1010933404324</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="81" /><w:bookmarkStart w:id="83" w:name="ref-Cohen2006" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Cohen, A. M., W. R. Hersh, K. Peterson, and Po-Yin Yen. 2006. “Reducing Workload in Systematic Review Preparation Using Automated Citation Classification.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of the American Medical Informatics Association : JAMIA</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">13 (2): 206–19.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId82"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1197/jamia.M1929</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="83" /><w:bookmarkStart w:id="85" w:name="ref-Cormack2014" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Cormack, Gordon V., and Maura R. Grossman. 2014. “Evaluation of Machine-Learning Protocols for Technology-Assisted Review in Electronic Discovery.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</w:t></w:r><w:r><w:t xml:space="preserve">, 153–62. SIGIR ’14. Gold Coast, Queensland, Australia: Association for Computing Machinery.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId84"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1145/2600428.2609601</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="85" /><w:bookmarkStart w:id="86" w:name="ref-modAL2018" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Danka, Tivadar, and Peter Horvath. n.d. “modAL: A Modular Active Learning Framework for Python.”</w:t></w:r></w:p><w:bookmarkEnd w:id="86" /><w:bookmarkStart w:id="88" w:name="ref-Hall2012" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Hall, Tracy, Sarah Beecham, David Bowes, David Gray, and Steve Counsell. 2012. “A Systematic Literature Review on Fault Prediction Performance in Software Engineering.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">IEEE Transactions on Software Engineering</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">38 (6): 1276–1304.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId87"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1109/TSE.2011.103</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="88" /><w:bookmarkStart w:id="90" w:name="ref-Kilicoglu2009" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Kilicoglu, H., D. Demner-Fushman, T. C. Rindflesch, N. L. Wilczynski, and R. B. Haynes. 2009. “Towards Automatic Recognition of Scientifically Rigorous Clinical Research Evidence.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of the American Medical Informatics Association</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">16 (1): 25–31.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId89"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10/bjkhh9</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="90" /><w:bookmarkStart w:id="92" w:name="ref-Le2014" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Le, Quoc V., and Tomas Mikolov. 2014. “Distributed Representations of Sentences and Documents.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">arXiv:1405.4053 [Cs]</w:t></w:r><w:r><w:t xml:space="preserve">, May.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId91"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">http://arxiv.org/abs/1405.4053</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="92" /><w:bookmarkStart w:id="94" w:name="ref-Lewis1994" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Lewis, David D., and Jason Catlett. 1994. “Heterogeneous Uncertainty Sampling for Supervised Learning.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Machine Learning Proceedings 1994</w:t></w:r><w:r><w:t xml:space="preserve">, edited by William W. Cohen and Haym Hirsh, 148–56. San Francisco (CA): Morgan Kaufmann.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId93"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1016/B978-1-55860-335-6.50026-X</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="94" /><w:bookmarkStart w:id="96" w:name="ref-Miwa2014" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Miwa, Makoto, James Thomas, Alison O’Mara-Eves, and Sophia Ananiadou. 2014. “Reducing Systematic Review Workload Through Certainty-Based Screening.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of Biomedical Informatics</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">51 (October): 242–53.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId95"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1016/j.jbi.2014.06.005</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="96" /><w:bookmarkStart w:id="98" w:name="ref-Nagtegaal2019" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Nagtegaal, Rosanna, Lars Tummers, Mirko Noordegraaf, and Victor Bekkers. 2019a. “Nudging Healthcare Professionals Towards Evidence-Based Medicine: A Systematic Scoping Review.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of Behavioral Public Administration</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">2 (2).</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId97"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/doi.org/10.30636/jbpa.22.71</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="98" /><w:bookmarkStart w:id="99" w:name="ref-Nagtegaal2019a" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">———. 2019b. “Nudging Healthcare Professionals Towards Evidence-Based Medicine: A Systematic Scoping Review.” Harvard Dataverse.</w:t></w:r></w:p><w:bookmarkEnd w:id="99" /><w:bookmarkStart w:id="100" w:name="ref-Ng2002" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Ng, Andrew Y., and Michael I. Jordan. 2002. “On Discriminative Vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Advances in Neural Information Processing Systems 14</w:t></w:r><w:r><w:t xml:space="preserve">, edited by T. G. Dietterich, S. Becker, and Z. Ghahramani, 841–48. MIT Press.</w:t></w:r></w:p><w:bookmarkEnd w:id="100" /><w:bookmarkStart w:id="102" w:name="ref-OMara-Eves2015" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">O’Mara-Eves, Alison, James Thomas, John McNaught, Makoto Miwa, and Sophia Ananiadou. 2015. “Using Text Mining for Study Identification in Systematic Reviews: A Systematic Review of Current Approaches.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Systematic Reviews</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">4 (1): 5.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId101"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1186/2046-4053-4-5</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="102" /><w:bookmarkStart w:id="103" w:name="ref-scikit-learn" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of Machine Learning Research</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">12: 2825–30.</w:t></w:r></w:p><w:bookmarkEnd w:id="103" /><w:bookmarkStart w:id="105" w:name="ref-PRISMA-PGroup2015" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">PRISMA-P Group, David Moher, Larissa Shamseer, Mike Clarke, Davina Ghersi, Alessandro Liberati, Mark Petticrew, Paul Shekelle, and Lesley A Stewart. 2015. “Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols (PRISMA-P) 2015 Statement.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Systematic Reviews</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">4 (1): 1.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId104"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1186/2046-4053-4-1</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="105" /><w:bookmarkStart w:id="106" w:name="ref-Ramos2003" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Ramos, Juan, and others. 2003. “Using Tf-Idf to Determine Word Relevance in Document Queries.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Proceedings of the First Instructional Conference on Machine Learning</w:t></w:r><w:r><w:t xml:space="preserve">, 242:133–42. Piscataway, NJ.</w:t></w:r></w:p><w:bookmarkEnd w:id="106" /><w:bookmarkStart w:id="108" w:name="ref-Reimers2019" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Reimers, Nils, and Iryna Gurevych. 2019. “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">arXiv:1908.10084 [Cs]</w:t></w:r><w:r><w:t xml:space="preserve">, August.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId107"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">http://arxiv.org/abs/1908.10084</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="108" /><w:bookmarkStart w:id="109" w:name="ref-Rehurek2010" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Řehůřek, Radim, and Petr Sojka. 2010. “Software Framework for Topic Modelling with Large Corpora.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</w:t></w:r><w:r><w:t xml:space="preserve">, 45–50. Valletta, Malta: ELRA.</w:t></w:r></w:p><w:bookmarkEnd w:id="109" /><w:bookmarkStart w:id="110" w:name="ref-Tong2001" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Tong, Simon, and Daphne Koller. 2001. “Support Vector Machine Active Learning with Applications to Text Classification.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Journal of Machine Learning Research</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">2 (Nov): 45–66.</w:t></w:r></w:p><w:bookmarkEnd w:id="110" /><w:bookmarkStart w:id="112" w:name="ref-vandeSchoot2017" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">van de Schoot, Rens, Marit Sijbrandij, Sonja D. Winter, Sarah Depaoli, and Jeroen K. Vermunt. 2017. “The GRoLTS-Checklist: Guidelines for Reporting on Latent Trajectory Studies.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Structural Equation Modeling: A Multidisciplinary Journal</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">24 (3): 451–67.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId111"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10/gdpcw9</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="112" /><w:bookmarkStart w:id="114" w:name="ref-Wallace2010" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Wallace, Byron C., Thomas A. Trikalinos, Joseph Lau, Carla Brodley, and Christopher H. Schmid. 2010. “Semi-Automated Screening of Biomedical Citations for Systematic Reviews.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">BMC Bioinformatics</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">11 (1): 55.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId113"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1186/1471-2105-11-55</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="114" /><w:bookmarkStart w:id="116" w:name="ref-Yu2018a" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Yu, Zhe, Nicholas A. Kraft, and Tim Menzies. 2018. “Finding Better Active Learners for Faster Literature Reviews.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Empirical Software Engineering</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">23 (6): 3161–86.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId115"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1007/s10664-017-9587-0</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="116" /><w:bookmarkStart w:id="118" w:name="ref-Yu2019" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Yu, Zhe, and Tim Menzies. 2019. “FAST2: An Intelligent Assistant for Finding Relevant Papers.”</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Expert Systems with Applications</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">120 (April): 57–71.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId117"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://doi.org/10.1016/j.eswa.2018.11.021</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p><w:bookmarkEnd w:id="118" /><w:bookmarkStart w:id="119" w:name="ref-Zhang2004" /><w:p><w:pPr><w:pStyle w:val="Bibliography" /></w:pPr><w:r><w:t xml:space="preserve">Zhang, Harry. 2004. “The Optimality of Naive Bayes.” In</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /></w:rPr><w:t xml:space="preserve">Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004</w:t></w:r><w:r><w:t xml:space="preserve">. Vol. 2.</w:t></w:r></w:p><w:bookmarkEnd w:id="119" /><w:bookmarkEnd w:id="120" /><w:sectPr /></w:body></w:document>