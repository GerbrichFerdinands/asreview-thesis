---
title: "Processing simulation output"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(rjson)
library(tidyverse)
library(knitr)
library(flextable)
library(officer)
```

This directory stores all files used to extract figures and statistics from the simulation study output.
The directory contains the following:

- `extract_plots.ipynb`, a jupyter notebook producing recall curves from the simulation output (Figure 1 and 2 in the manuscript)
- `extract_results.ipynb`, a jupyter notebook extracting `.json` files containing statistics from the simulation output (WSS, RRF, ATD in table 2, 3, and 4 in the manuscript)
- `one_seed`, containing all plots and data produced by the two jupyter notebooks above.
- `README.Rmd` containing R-code to transform the .json files into readable tables for the manuscript.
- `output` contains the abovementioned tables, stored as .RDS files.  


## Define functions for reading simulation output 
```{r}
data <- readRDS("../simulation_study/R/00_datasets.RDS")
models <-c("BCTD", "LCDD", "LCTD", "RCDD", "RCTD", "SCDD", "SCTD")
names(models) <- c("NB + TF-IDF", "LR + D2V", "LR + TF-IDF", "RF + D2V", "RF + TF-IDF", "SVM + D2V", "SVM + TF-IDF" )

# function that reads results for all 15 runs
read_results <- function(m){
   files = list.files(paste0("one_seed/statistics/", m), pattern = "all.json", recursive = TRUE)
  # names of the files are the data
  names(files) <- str_split(files, "/", simplify = TRUE)[,1]
  # read data
  dat <- lapply(files, function(x) fromJSON(file = paste0("one_seed/statistics/", m, "/", x)))
  
  # extract wss, rrf, and loss
  dat <- map(dat, `[`, c("wss", "rrf", "loss"))

  # transorm into dataframe
  dat <- map_dfr(dat, ~ as.data.frame(.x), .id = "dataset")
  
  # add model name
  dat <- dat %>% 
    mutate(model = names(models[models == m]))

  return(dat)
}

# function for extracting all separate runs 
read_trials <- function(m){
   files <- list.files(paste0("one_seed/statistics/", m), pattern = "results_", recursive = TRUE, full.names=TRUE)
  # names of the files are the data
  names(files) <- str_split(files, "/", simplify = TRUE)[,9]
  
  # read data
  dat <- lapply(files, function(x) fromJSON(file = x))
  
  # extract wss, rrf, and loss
  dat <- map(dat, `[`, c("wss", "rrf", "loss"))

  # transorm into dataframe
  dat <- map_dfr(dat, ~ as.data.frame(.x), .id = "dataset")
  
  # add model name
  dat <- dat %>% 
    mutate(model = names(models[models == m]))

  return(dat)
}


# ATD needs to be adjusted for 1 prior inclusion and 1 prior exclusion! 
# compute adjusted ATD to make it equal to the area above the curve
datastats <- readRDS("datastats.RDS") %>%
  select(Dataset, candidates_test, incl_test) %>%
  # account for 1 prior exclusion and 1 prior inclusion
  mutate(n_1 = incl_test, n_excl = candidates_test-n_1, n_1_noprior = incl_test-1, candidates_noprior = candidates_test -1) %>%
  mutate(ratio = (n_1_noprior/n_1)/(candidates_noprior/candidates_test))

datastats$dataset <- c("ace", "nudging", "ptsd", "software", "virus", "wilson")
atdratio <- datastats %>%
  select(dataset, ratio)
```

## Load results for 15 separate trials
```{r}
# read all 15 trials separately
runs <- lapply(models, FUN = read_trials)

# all in one dataframe
runs <- do.call("rbind", runs)

# convert loss (ttd) to percentage 
runs$loss <- runs$loss*100
# adjust loss to N_1 : N_1-1 (to the prior inclusions)
runs <- left_join(runs, atdratio, by = "dataset")
runs <- runs %>%
  mutate(loss = loss/ratio) %>%
  select(-ratio)

# save results file 
saveRDS(runs, "output/runs.RDS")
```

Compute standarad deviation from the 15 separate trials.
```{r}
# compute standard deviation (bootstrapped)
sdruns <- 
  runs %>%
  select(dataset, model, wss.95, rrf.10, loss) %>% 
  group_by(model, dataset) %>%
  summarise(sdwss.95 = sd(wss.95),
            sdrrf.10 = sd(rrf.10),
            sdloss = sd(loss))

saveRDS(sdruns, "output/sdruns.RDS")
```

## Load results as means over all 15 trials  
```{r}
# extract results for all models
# list for models separately
results <- lapply(models, read_results)

# all in one dataframe
results <- do.call("rbind", results)

# convert loss (ttd) to percentage 
results$loss <- results$loss*100
# adjust loss to N_1 : N_1-1
results <- left_join(results, atdratio, by = "dataset")

results <- results %>%
  mutate(loss = loss/ratio) %>%
  select(-ratio)

# save results file 
saveRDS(results, "output/results.RDS")
```

Create table for manuscript (all means over 15 runs)
```{r}
tabres <- 
  results %>%
  pivot_wider(names_from = dataset, values_from = c("wss.95", "wss.99", "wss.100", "rrf.5", "rrf.10", "rrf.20", "loss"))

# table of mean statistics over all runs 
stabres <- 
tabres %>%
  # select statistics
  select(model,
         starts_with("wss.95"),
         starts_with("rrf.10"), 
         starts_with("loss")) %>%
  # reorder datasets
  select(model,
         ends_with("nudging"),
         ends_with("ptsd"),
         ends_with("software"),
         ends_with("ace"),
         ends_with("virus"),
         ends_with("wilson")
         )

saveRDS(stabres, "output/tabresults.RDS")

knitr::kable(stabres, format = "markdown", digits = 1)
```

